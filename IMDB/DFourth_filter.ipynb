{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"perfect_datasets/perfect_dataset_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1000, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(ds[\"tags\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_similar_movie_indices = similarity.argsort()[0][::-1][1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "suggg = []\n",
    "sug_d={\"name\":[]}\n",
    "\n",
    "# simm = similarity[0]\n",
    "\n",
    "for i in similarity:\n",
    "    a = sorted(list(enumerate(similarity[c])), reverse=True, key=lambda x: x[1])\n",
    "    c2=0\n",
    "    temp = []\n",
    "    temp_c = {\"name\": f\"{ds.iloc[a[0][0]].title}\"}\n",
    "\n",
    "    for j in range(1, 25):\n",
    "        temp_c[\"name\"] += f\",{ds.iloc[a[j][0]].title}\"\n",
    "\n",
    "    suggg.append(temp)\n",
    "    sug_d[\"name\"].append(temp_c[\"name\"])\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': [\"Harry Potter and the Philosopher's Stone,A Skin Too Few: The Days of Nick Drake,La Mission,The Candy Tangerine Man,Knockout,The Hired Hand,Prom Queen: The Marc Hall Story,The Mutilator,Scrooge,Spud 3: Learning to Fly,Harry Potter and the Goblet of Fire,Slipstream,Summer Holiday,The Prisoner,Waterland,Harry & Son,The Adventures of Elmo in Grouchland,Haiku Tunnel,Outing Riley,Harry and Tonto,Six Ways to Sunday,The Comedian,Rites of Passage,Carried Away,Song of the South\"]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c=0\n",
    "# suggg = []\n",
    "# sug_d={\"name\":[]}\n",
    "\n",
    "# simm = similarity[4273]\n",
    "# # simm = similarity[15311]\n",
    "# # simm = similarity[11757]\n",
    "\n",
    "# a = sorted(list(enumerate(simm)), reverse=True, key=lambda x: x[1])\n",
    "# c2=0\n",
    "# temp = []\n",
    "# temp_c = {\"name\": f\"{ds.iloc[a[0][0]].title}\"}\n",
    "# for j in range(1, 25):\n",
    "#     temp_c[\"name\"] += f\",{ds.iloc[a[j][0]].title}\"\n",
    "# suggg.append(temp)\n",
    "# sug_d[\"name\"].append(temp_c[\"name\"])\n",
    "\n",
    "# sug_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ds = pd.DataFrame(sug_d)\n",
    "d_ds.to_csv(\"./perfect_datasets/perfect_datasets_v4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.72 GiB for an array with shape (32185, 32185) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\ML_project\\IMDB\\DFourth_filter.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ML_project/IMDB/DFourth_filter.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m cv \u001b[39m=\u001b[39m CountVectorizer(max_features\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, stop_words\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ML_project/IMDB/DFourth_filter.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m vectors \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mfit_transform(ds[\u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/ML_project/IMDB/DFourth_filter.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m similarity \u001b[39m=\u001b[39m cosine_similarity(vectors)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ML_project/IMDB/DFourth_filter.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m num_clusters \u001b[39m=\u001b[39m (similarity\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ML_project/IMDB/DFourth_filter.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39mnum_clusters, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mihir\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mihir\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1585\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1582\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1583\u001b[0m     Y_normalized \u001b[39m=\u001b[39m normalize(Y, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1585\u001b[0m K \u001b[39m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39mdense_output)\n\u001b[0;32m   1587\u001b[0m \u001b[39mreturn\u001b[39;00m K\n",
      "File \u001b[1;32mc:\\Users\\mihir\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    191\u001b[0m         ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(a, b)\n\u001b[0;32m    192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39m b\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    196\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[0;32m    197\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[0;32m    198\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[0;32m    199\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m ):\n\u001b[0;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.72 GiB for an array with shape (32185, 32185) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "ds = pd.read_csv(\"./perfect_datasets/perfect_dataset_v3.csv\")\n",
    "ds_overview = pd.read_csv(\"D:/DATA_Sets/perfect_dataset_v1.csv\")\n",
    "\n",
    "cv = CountVectorizer(max_features=1000, stop_words=\"english\")\n",
    "\n",
    "vectors = cv.fit_transform(ds[\"tags\"]).toarray()\n",
    "\n",
    "similarity = cosine_similarity(vectors)\n",
    "\n",
    "num_clusters = (similarity.shape[0]*10)//100\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "cluster_labels = kmeans.fit_predict(similarity)\n",
    "\n",
    "ds[\"cluster_label\"] = cluster_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
